{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2.xfeatures2d import SIFT_create\n",
    "import os\n",
    "import configparser\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.cluster as cls\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform,mahalanobis,sqeuclidean,seuclidean,correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSG:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sift = SIFT_create()#nfeatures,contrastThreshold,edgethreshold,nOctaveLayers = 3, sigma = 1.5\n",
    "        self.classifier = SVC(C=1, kernel='rbf', probability=True) #C inversely proportional to regularisation\n",
    "        self.features_len = []\n",
    "        self.all_features = np.array([[]])\n",
    "        self.trainimage_label = []\n",
    "        self.test_set = np.array([[]])\n",
    "        self.testimage_list = []\n",
    "        self.testimage_label = []\n",
    "        self.config_path = '/home/soliton/work/projects/dataset_generator/models/dsgconfig.ini'\n",
    "        self.configure()\n",
    "    \n",
    "    def configure(self):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(self.config_path)\n",
    "        self.positive_training_images = config['Paths']['positive_training_images']\n",
    "        self.random_training_images = config['Paths']['random_training_images']\n",
    "        self.positive_testing_images = config['Paths']['positive_testing_images']\n",
    "        self.random_testing_images = config['Paths']['random_testing_images']\n",
    "        self.resize_height = int(config['Image']['resize_height'])\n",
    "        self.resize_width = int(config['Image']['resize_width'])\n",
    "        self.number_of_clusters = int(config['Cluster']['number_of_clusters'])\n",
    "    \n",
    "    def load_trainingset(self, path, trainimage_label):\n",
    "        print(\"loading trainingset\")\n",
    "        for image in os.listdir(path):\n",
    "            self.trainingset(path+'/'+image, trainimage_label)\n",
    "    \n",
    "    def trainingset(self, image_path, trainimage_label):\n",
    "        des = self.get_features(image_path)\n",
    "        #cv2.imshow('img',des)\n",
    "        #cv2.waitKey(1000)\n",
    "        #cv2.destroyAllWindows()\n",
    "        self.trainimage_label.append(trainimage_label)\n",
    "        self.features_len.append(len(des))\n",
    "        if(self.all_features.shape == (1, 0)):\n",
    "            self.all_features = np.array(des)\n",
    "        else:\n",
    "            self.all_features = np.concatenate((self.all_features, des), axis=0)\n",
    "        \n",
    "    def get_features(self, path):\n",
    "        img = cv2.imread(path, 1)\n",
    "        re_img=cv2.resize(img, (self.resize_height,self.resize_width))\n",
    "        gray= cv2.cvtColor(re_img,cv2.COLOR_BGR2GRAY)\n",
    "        kp,des = self.sift.detectAndCompute(gray, None)\n",
    "        return des\n",
    "    \n",
    "    def cluster(self):\n",
    "        self.k_means()\n",
    "        #self.affinityprop()\n",
    "        print(len(self.centroids),len(self.all_features))\n",
    "    \n",
    "    def affinityprop(self): \n",
    "        s_matrix = squareform(pdist(self.all_features, metric='euclidean'))\n",
    "        self.centroids, self.cluster_labels = cls.affinity_propagation(s_matrix)\n",
    "    \n",
    "    def k_means(self):\n",
    "         self.centroids, self.cluster_labels, _ = cls.k_means(self.all_features, self.number_of_clusters)\n",
    "  \n",
    "    def meanshift(self):\n",
    "        self.centroids, self.cluster_labels = cls.mean_shift(self.all_features, bandwidth = 100)\n",
    "    \n",
    "    def train(self):\n",
    "        self.load_trainingset(self.positive_training_images,0)\n",
    "        self.load_trainingset(self.random_training_images,1)\n",
    "        self.cluster()\n",
    "        training_data = np.zeros((len(self.trainimage_label), max(self.cluster_labels)+1))\n",
    "        feature_index = 0\n",
    "        for image in range(len(self.trainimage_label)):\n",
    "            for feature in range(self.features_len[image]):\n",
    "                training_data[image][self.cluster_labels[feature_index]] = 1 + training_data[image][self.cluster_labels[feature_index]]\n",
    "                feature_index += 1\n",
    "        self.classifier.fit(training_data, self.trainimage_label)\n",
    "    \n",
    "    def load_testset(self, path, flag = -1):\n",
    "        print(\"loading testset\")\n",
    "        for image in os.listdir(path):\n",
    "            self.testimage_list.append(image)\n",
    "            self.testimage_label.append(flag)\n",
    "            self.testset(path+'/'+image)\n",
    "\n",
    "    \n",
    "    def testset(self, imagepath):\n",
    "        test_set = np.zeros((1, max(self.cluster_labels)+1))\n",
    "        des = self.get_features(imagepath)\n",
    "        for feature in des:\n",
    "            low_dif, bst_label = 0,0 \n",
    "            for label in range(len(self.centroids)):\n",
    "                dist = sum(abs(self.centroids[label]-feature))\n",
    "                if(low_dif == 0 or dist <= low_dif):\n",
    "                    low_dif = dist\n",
    "                    bst_label = label\n",
    "            test_set[0][bst_label] += 1 \n",
    "        if(self.test_set.shape == (1,0)):\n",
    "            self.test_set = np.array(test_set)\n",
    "        else:\n",
    "            self.test_set = np.concatenate((self.test_set, test_set), axis=0)\n",
    "            \n",
    "    def predict(self):\n",
    "        self.load_testset(self.positive_testing_images,0)\n",
    "        self.load_testset(self.random_testing_images,1)\n",
    "        return self.format_result(self.classifier.predict_proba(self.test_set)[:,0])\n",
    "    \n",
    "    def format_result(self, result):\n",
    "        self.testimage_list = [x for _,x in sorted(zip(result,self.testimage_list))]\n",
    "        self.testimage_label = [x for _,x in sorted(zip(result,self.testimage_label))]\n",
    "        result.sort()\n",
    "        result = result[::-1]\n",
    "        self.testimage_list.reverse()\n",
    "        self.testimage_label.reverse()\n",
    "        result = [[value0,value1, value2] for value0,value1, value2 in zip(self.testimage_list,self.testimage_label,result)]\n",
    "        print(self.classifier.classes_)\n",
    "        return result\n",
    "        \n",
    "    def store_model(self):\n",
    "        model = {}\n",
    "        model['classfier'] = self.classifier\n",
    "        model['centroids'] = self.centroids\n",
    "        model['cluster_labels'] = self.cluster_labels\n",
    "        with open(model_path,'wb') as f:\n",
    "            pickle.dump(model, f) \n",
    "    \n",
    "    def load_model(self):\n",
    "        with open(model_path,'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        self.sift = cv2.xfeatures2d.SIFT_create() \n",
    "        self.classifier = model['classfier']\n",
    "        self.centroids = model['centroids']\n",
    "        self.cluster_labels = model['cluster_labels']\n",
    "        \n",
    "    def score(self,predicted_label):\n",
    "        x=0\n",
    "        for a,b in zip(predicted_label,self.testimage_label):\n",
    "            if(a == b):\n",
    "                x = x+1  \n",
    "        return x/len(self.testimage_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading trainingset\n",
      "loading trainingset\n",
      "500 4061\n",
      "loading testset\n",
      "loading testset\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dsg = DSG()\n",
    "    dsg.train()\n",
    "    result = dsg.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chair.jpg', 1, 0.5195308862325948]\n",
      "['download.jpeg', 0, 0.5165659053151621]\n",
      "['images (1).jpeg', 0, 0.51298861620849]\n",
      "['images.jpeg', 1, 0.5124264061225745]\n",
      "['download (1).jpeg', 0, 0.5121821256906787]\n",
      "['images.jpeg', 0, 0.5118527580730468]\n",
      "['images (5).jpeg', 1, 0.5114576537421237]\n",
      "['images (14).jpeg', 0, 0.5113690902109758]\n",
      "['images (9).jpeg', 0, 0.5110958449924237]\n",
      "['car.jpeg', 0, 0.5110111597888606]\n",
      "['images (6).jpeg', 1, 0.5105704601588709]\n",
      "['truck', 1, 0.5103817458563633]\n",
      "['images (2).jpeg', 0, 0.5102949475436337]\n",
      "['images (4).jpeg', 1, 0.5101636791778007]\n",
      "['images (4).jpeg', 0, 0.5099916006402694]\n",
      "['images (3).jpeg', 0, 0.5098504813081952]\n",
      "['images (12).jpeg', 1, 0.5094777600818227]\n",
      "['images (6).jpeg', 0, 0.5094619712413632]\n",
      "['images (3).jpeg', 1, 0.5093070460013708]\n",
      "['images (11).jpeg', 0, 0.5091862615296975]\n",
      "['images (5).jpeg', 0, 0.5091452203730079]\n",
      "['images (2).jpeg', 1, 0.5089345605716861]\n",
      "['images (10).jpeg', 0, 0.508719027444864]\n",
      "['images (8).jpeg', 0, 0.5085863536379127]\n",
      "['images (1).jpeg', 1, 0.5085155558519899]\n",
      "['images (7).jpeg', 0, 0.5081285605221258]\n",
      "['car2.jpeg', 0, 0.5074713735910023]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "for i in result:\n",
    "    print (i)\n",
    "    x.append(i[2]<0.5)\n",
    "x = list(map(int,x))\n",
    "print(x)\n",
    "print(dsg.score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
